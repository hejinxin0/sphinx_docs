# 3D人体姿态估计

[【万字长文1！人体姿态估计(HPE)入门教程】 - 知乎](https://zhuanlan.zhihu.com/p/596043913)

 [深度学习的三维人体姿态估计综述.pdf](./papers/深度学习的三维人体姿态估计综述.pdf) 

## 3D 人体姿态估计常见流程

| 步骤 | 模块                     | 描述                                                         |
| ---- | ------------------------ | ------------------------------------------------------------ |
| 1️⃣    | **输入数据**             | 单张图像、视频帧或多视角图像                                 |
| 2️⃣    | **人体检测（可选）**     | 用目标检测器（如 YOLO、Faster R-CNN）获取人体框，裁出人像    |
| 3️⃣    | **2D 关键点检测**        | 使用如 OpenPose、HRNet、DETR 等模型估计 2D 关节点位置        |
| 4️⃣    | **2D → 3D 回归或拟合**   | 两种方式： ① 直接回归 3D 关节点位置（基于深度学习） ② 拟合 SMPL/SMPL-X 参数模型（优化/回归） |
| 5️⃣    | **相机参数估计（可选）** | 回归或优化相机位姿（如弱透视参数 pred_cam）                  |
| 6️⃣    | **3D 姿态重建**          | 得到 3D joints 或 mesh（顶点、网格）                         |
| 7️⃣    | **可视化或应用**         | 3D 渲染显示，驱动动画，动作识别，AR/VR等                     |

------



Weak Perspective Camera（弱透视投影）IWP Camera（Intrinsic Weak Perspective Camera，内在弱透视相机）：https://github.com/open-mmlab/mmhuman3d/blob/main/docs_zh-CN/cameras.md

四元数、轴角（旋转向量）、欧拉角表示

##  两种主要方法

### 基于回归的方式：

- 输入图像 → 网络直接输出 3D joints 或 SMPL 参数
- 快速，适合实时应用
- 示例模型：**SPIN**, **VIBE**, **HybrIK**, **ROMP**
-  [HMR](https://akanazawa.github.io/hmr/) (CVPR'2018)
-  [VIBE](https://github.com/mkocabas/VIBE) (CVPR'2020)
-  [HybrIK](https://jeffli.site/HybrIK/) (CVPR'2021)

### 基于优化的方式：

- 使用 2D joints 或 3D prior → 优化 SMPL 参数拟合数据
- 更准确，适合精度要求高的场景
- 示例方法：**SMPLify**, **SMPLify-X**, **PIXIE**

------

## 常见输出形式

| 类型            | 输出内容                                          |
| --------------- | ------------------------------------------------- |
| **3D joints**   | N 个关节点的 XYZ 坐标                             |
| **Mesh (SMPL)** | 6890 个顶点的 3D mesh                             |
| **SMPL 参数**   | pose（旋转向量）、shape（β）、translation         |
| **Camera 参数** | 弱透视相机参数（如 `pred_cam`）或 full extrinsics |

## openpose

项目页面：https://github.com/CMU-Perceptual-Computing-Lab/openpose

openpose的人体关键点：https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/02_output.md

`pose_keypoints_2d` : 25

`face_keypoints_2d` : 70

`hand_left_keypoints_2d` : 21

`hand_right_keypoints_2d` : 21

| 身体模型 BODY_25                                             |                                                              |                                                              |
| ------------------------------------------------------------ | :----------------------------------------------------------: | ------------------------------------------------------------ |
| <img src="assets/keypoints_pose_25.png" alt="img" style="zoom:15%;" /> | <img src="assets/keypoints_face.png" alt="img" style="zoom: 50%;" /> | <img src="assets/keypoints_hand.png" alt="img" style="zoom: 33%;" /> |

MeGA：https://github.com/conallwang/MeGA/tree/temp_empty

## EasyMocap

项目页面：https://github.com/zju3dv/EasyMocap

X-Avatar：https://skype-line.github.io/projects/X-Avatar/

（1）openpose 估计人体 2D 关键点

（2）多视角关键点批量三角化 `batch_triangulate`

（3）优化 SMPL (SMPL-X) 体型参数 `optimizeShape`

通过调整体型参数 `shapes` 来使模型的预测关键点与真实的3D关键点对齐。

根据给定的 3D 关键点和骨架结构（`kintree`），计算每个骨骼的长度（`limb_length`）以及每对关节的置信度（`limb_conf`）

**优化目标**：

- `loss_dict['s3d']` : 通过最小化关节间骨长的误差，确保模型的骨长与真实数据的骨长一致
- `loss_dict['reg_shapes']` : 对体型参数 `shapes` 进行 L2 正则化，以避免过拟合
- `loss_dict['init_shape']` : 如果提供了初始体型，将当前体型与初始体型之间的差异作为额外的损失项，保持形状的平滑性

**优化过程**：使用 **LBFGS** 优化器对体型参数 `shapes` 进行优化，通过反向传播调整参数以最小化损失函数

（4）多阶段优化 `multi_stage_optimize`

Optimize global RT

Optimize 3D Pose

Optimize 2D Pose

